import requests
from bs4 import BeautifulSoup
import json
from datetime import datetime

def scrape_taishin_credit_cards():
    url = "https://www.taishinbank.com.tw/TSB/personal/credit-card/overview/"
    headers = {
        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'
    }
    
    response = requests.get(url, headers=headers)
    soup = BeautifulSoup(response.text, 'html.parser')
    
    credit_cards = {
        "cashback": [],
        "dining": [],
        "overseas": [],
        "mileage": []
    }
    
    card_sections = soup.find_all('div', class_='card_item')
    
    for index, card in enumerate(card_sections, start=1):
        name = card.find('h3', class_='card_name').text.strip()
        benefits = card.find('p', class_='card_text').text.strip()
        
        # 簡單的分類邏輯，實際應用中可能需要更複雜的分類方法
        category = "cashback"
        if "飲食" in benefits or "餐廳" in benefits:
            category = "dining"
        elif "海外" in benefits or "國外" in benefits:
            category = "overseas"
        elif "哩程" in benefits or "里程" in benefits:
            category = "mileage"
        
        card_info = {
            "name": name,
            "bank": "台新銀行",
            "benefits": benefits,
            "rank": index
        }
        
        credit_cards[category].append(card_info)
    
    # 將數據保存為 JSON 文件
    with open('credit_card_data.json', 'w', encoding='utf-8') as f:
        json.dump(credit_cards, f, ensure_ascii=False, indent=2)
    
    print("Data has been scraped and saved to credit_card_data.json")

if __name__ == "__main__":
    scrape_taishin_credit_cards()